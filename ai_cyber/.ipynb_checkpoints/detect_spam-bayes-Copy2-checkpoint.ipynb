{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Spam filter using Naive Bayes classifier\"\"\"\n",
    "\n",
    "\n",
    "import email.parser \n",
    "import os, sys, stat\n",
    "from tqdm import tqdm\n",
    "import re, cgi\n",
    "import math, pickle\n",
    "from decimal import Decimal\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extract_content(filename):\n",
    "\t''' Extract the subject and payload from the .eml file.'''\n",
    "\twith open(filename, 'rb') as fp:\n",
    "\t\tmsg = email.message_from_bytes(fp.read())\n",
    "\tsub = msg.get('subject')\n",
    "\t#If it is a multipart message, get_payload returns a list of parts.\n",
    "\tif msg.is_multipart():\n",
    "\t\tpayload = msg.get_payload()[0]\t\n",
    "\t\tpayload = payload.as_bytes() #We will consider the body as bytes so it is easier to decode into a unicode string.\n",
    "\telse:\n",
    "\t\tpayload =  msg.get_payload()\n",
    "\treturn \"{}\\n{}\" . format(sub, payload)\n",
    "\n",
    "def get_text_from_email(mail):\n",
    "\t\"\"\" Removes html tags and punctuations.\"\"\"\n",
    "\ttag_re = re.compile(r'(<!--.*?-->|<[^>]*>)')\n",
    "\n",
    "\t# Remove well-formed tags, fixing mistakes by legitimate users\n",
    "\tmail = tag_re.sub('', mail)\n",
    "\n",
    "\t# Clean up anything else by escaping\n",
    "\tmail = cgi.escape(mail)\n",
    "\t\n",
    "\tmail = re.sub(r'([\\\\][n|t|x])', ' ', mail)                           #Removes \\n\\t\\b strings\n",
    "\tmail = re.sub(r'[=*/&;.,/\\\" ?:<>\\[\\]\\(\\)\\{\\}\\|%#`~\\\\]', ' ', mail)   #Removes punctuations\n",
    "\tmail = re.sub(r'[- _=+]{2,}|(?=\\s)[-_]|[-_](?=\\s)', ' ', mail)       #Removes unnecessary hiphens and underscores\n",
    "\tmail = re.sub(r'[\\d]', ' ', mail)                                    #Revoves all digits\n",
    "\tmail = re.sub(r'[\\'!=+]', '', mail)                                  #Replaces these punctuations with null string\n",
    "\treturn mail.lower()\n",
    "\n",
    "\n",
    "def preprocess(mail):\n",
    "\t\"\"\"Preprocess data\"\"\"\n",
    "\t# Currently just one preprocessing step.\n",
    "\tmail = get_text_from_email(mail)\n",
    "\treturn mail\n",
    "\n",
    "\n",
    "def add_words_to_dict(word_set, word_dict, ham):\n",
    "\t\"\"\"Checks if the word is presnt or not and increments its respective value\"\"\"\n",
    "\tfor word in word_set:\n",
    "\t\tif word not in word_dict:\n",
    "\t\t\tword_dict[word] = {'spam_count': 0, 'ham_count': 0}\n",
    "\t\tif ham:\n",
    "\t\t\tword_dict[word]['ham_count'] = word_dict[word]['ham_count'] + 1\n",
    "\t\telse:\n",
    "\t\t\tword_dict[word]['spam_count'] = word_dict[word]['spam_count'] + 1 \n",
    "\n",
    "def calculate_spaminess(word, word_dict, total_ham, total_spam):\n",
    "\t\"\"\" Calculate the probability of a message being spam provided that the word is present.\"\"\"\n",
    "\n",
    "\tpr_s, pr_h = 0.5, 0.5  #Assumming equal probability for both ham and spam\n",
    "\tthreshold = 2   #Strength factor to handle rare words\n",
    "\ttotal_occurance = word_dict[word]['spam_count'] + word_dict[word]['ham_count']  #Total number of times the word has occured in both ham and spam\n",
    "\tfreq_s = word_dict[word]['spam_count'] / total_spam \n",
    "\tfreq_h = word_dict[word]['ham_count'] / total_ham\n",
    "\tspamminess = (freq_s * pr_s) / (freq_s * pr_s + freq_h * pr_h)  #The probability that a given mail is spam, provided that this word is present.\n",
    "\tcorrected_spaminess = (0.3 * threshold + total_occurance * spamminess) / (threshold + total_occurance)  #Considering the strength factor.\n",
    "\tword_dict[word]['spaminess'] = corrected_spaminess   \n",
    "\n",
    "def generate_dictionary(files, labels):\n",
    "\t\"\"\"Generates a dictionary of all the words in both ham and spam mails\"\"\"\n",
    "\t#Initializing variables\n",
    "\titerator = 0\n",
    "\tword_dict = {}\n",
    "\ttotal_spam = 0\n",
    "\ttotal_ham = 0\n",
    "\n",
    "\tfor file in tqdm(files):\n",
    "\t\t#Read and extract mail contents\n",
    "\t\ttry:\n",
    "\t\t\tmail = extract_content(file)\n",
    "\t\texcept:\n",
    "\t\t\tprint(\"Corrupted File {}\" . format(file))\n",
    "\t\t# Prepare data\n",
    "\t\tmail = preprocess(mail)\n",
    "\t\tword_list = [s for s in mail.split()]\n",
    "\t\tword_set = set(word_list)\n",
    "\n",
    "\t\t# Incrementing HAM/SPAM count\n",
    "\t\tham = (True if (labels[iterator].split()[0]) == \"spam\" else False)\n",
    "\t\tif ham:\n",
    "\t\t\ttotal_ham += 1\n",
    "\t\telse:\n",
    "\t\t\ttotal_spam += 1\n",
    "\n",
    "\t\tadd_words_to_dict(word_set, word_dict, ham)\n",
    "\t\titerator += 1\n",
    "\tfor word in word_dict:\n",
    "\t\tcalculate_spaminess(word, word_dict, total_ham, total_spam)\n",
    "\twith open('word_dict.pickle', 'wb') as f:\n",
    "\t\tpickle.dump(word_dict, f)\n",
    "\treturn word_dict\n",
    "\n",
    "def get_scores(expected, predicted):\n",
    "\t\"\"\" Compares predicted and expected values and returns various metrics.\"\"\"\n",
    "\tscores = {}\n",
    "\t# _ implies we do not care about that metric.\n",
    "\t_, scores['False Positives'], scores['False Negatives'], _= confusion_matrix(expected, predicted).ravel()\n",
    "\tscores['Precision'], scores['Recall'], scores['F_score'], _= precision_recall_fscore_support(expected, predicted, average='macro')\n",
    "\treturn scores\n",
    "\n",
    "def training(files, labels):\n",
    "\t\"\"\"Trains the model and returns a word dictionary\"\"\"\n",
    "\ttry:\n",
    "\t\twith open('word_dict.pickle', 'rb') as f:\n",
    "\t\t\tprint(\"Found pickle file. Skipping training\")\n",
    "\t\t\tword_dict = pickle.load(f)\n",
    "\texcept:\n",
    "\t\t# Generate Dictionary\n",
    "\t\tword_dict = generate_dictionary(files, labels)\n",
    "\n",
    "\treturn word_dict\n",
    "\n",
    "def predict(files, word_dict):\n",
    "\t\"\"\"Predicts values using the word dictionary and returns a list of predictions\"\"\"\n",
    "\tpredictions = []\n",
    "\tfor file in tqdm(files):\n",
    "\t\t#Read and extract mail contents\n",
    "\t\ttry:\n",
    "\t\t\tmail = extract_content(file)\n",
    "\t\texcept:\n",
    "\t\t\tprint(\"Corrupted File {}\" . format(file))\n",
    "\t\t\n",
    "\t\t# Prepare data\n",
    "\t\tmail = preprocess(mail)\n",
    "\t\tword_list = [s for s in mail.split()]\n",
    "\t\tword_set = set(word_list)\n",
    "\n",
    "\t\tn = 0\n",
    "\t\tspaminess_list = []\n",
    "\t\tfor word in word_set:\n",
    "\t\t\tif word not in word_dict:\n",
    "\t\t\t\tcontinue              \t\t\t\t\t\t# Ignore new words (for now)\n",
    "\t\t\t\tspaminess = 0.6       \t\t\t\t\t\t# Or... assume it is slightly spam ( Gives better FP, but lower f-score)\n",
    "\t\t\telse:\n",
    "\t\t\t\tspaminess = word_dict[word]['spaminess']\n",
    "\t\t\t\tif spaminess < 0.6 and spaminess > 0.4:\n",
    "\t\t\t\t\tcontinue                                #ignore the word if spaminess is neutral\n",
    "\t\t\tspaminess_list.append(spaminess)\n",
    "\n",
    "\t\t# Adding up all the word probabilities\n",
    "\t\tfor spaminess in spaminess_list:\n",
    "\t\t\tn +=  (math.log(1-spaminess) - math.log(spaminess))\n",
    "\t\tprobability = 1 / (1 + Decimal(math.e) ** Decimal(n))\n",
    "\t\t\n",
    "\t\t# Predicting \n",
    "\t\tif probability > 0.8:\n",
    "\t\t\tprediction = '0'\n",
    "\t\telse:\n",
    "\t\t\tprediction = '1'\n",
    "\t\tpredictions.append(prediction)\n",
    "\treturn predictions\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "\t# Default paths for all the inputs. Overrided if script not in the same locations as them.\n",
    "# \ttrain = './trec07p/data'\n",
    "# \ttest = './trec07p/data'\n",
    "\n",
    "\tspam = './trec07p/full'\n",
    "\n",
    "\t# Getting user input if defaults are not valid\n",
    "\tprint(\"Please make sure the script is in the same directory as the Training and testing folders.\")\n",
    "\tif not (os.path.isdir(train) and os.path.isdir(test) and os.path.exists(spam)):\n",
    "\t\tprint(\"Testing and training datasets not found: \")\n",
    "\t\ttrain = input(\"Enter training dataset path: \")\n",
    "\t\ttest = input(\"Enter testing dataset path: \")\n",
    "\t\tspam = input(\"Enter labels file path: \")\n",
    "\t\n",
    "\t# Getting training and testing files\n",
    "    files = sorted([os.path.join(test, file) for file in os.listdir(test)])\n",
    "\ttrain_files = files[:3000]\n",
    "\ttest_files = files[3000:]\n",
    "\t#files = train_files + test_files\n",
    "\tprint(\"Found the datasets.\")\n",
    "\t\n",
    "\t# Spam labels\n",
    "\twith open(spam, 'r') as f:\n",
    "\t\tlabels = [line.split()[0] for line in f.readlines()]\n",
    "\ttrain_labels = labels[:3000]\n",
    "\ttest_labels = labels[3000:]\n",
    "\n",
    "\t# Training our model\n",
    "\tprint(\"Training the model...\")\n",
    "\tword_dict = training(train_files, train_labels)\n",
    "\t\n",
    "\t# Predicting labels for both training and testing data.\n",
    "\tprint(\"Testing on both training and testing datasets...\")\n",
    "\tpredictions = predict(files, word_dict )\n",
    "\ttrain_predictions = predictions[:3000]\n",
    "\ttest_predictions = predictions[3000:]\n",
    "\n",
    "\t# Get respective scores\n",
    "\ttest_scores = get_scores(test_labels, test_predictions)\n",
    "\ttrain_scores = get_scores(train_labels, train_predictions)\n",
    "\tcombined_scores = get_scores(labels, predictions)\n",
    "\n",
    "\t# Output results onto the console\n",
    "\tprint(\"\\nTraining Scores:\")\n",
    "\tfor key, value in sorted(train_scores.items()):\n",
    "\t\tprint(\"{:15} : {:.5}\" .format(key, float(value)))\n",
    "\tprint(\"\\nTesting Scores: \")\n",
    "\tfor key, value in sorted(test_scores.items()):\n",
    "\t\tprint(\"{:15} : {:.5}\" .format(key, float(value)))\n",
    "\tprint(\"\\nCombined Scores: \")\n",
    "\tfor key, value in sorted(combined_scores.items()):\n",
    "\t\tprint(\"{:15} : {:.5}\" .format(key, float(value)))\n",
    "\n",
    "\t# Creating a results file. Pandas object is used to help format our output.\n",
    "\tmails = {}\n",
    "\tmails['files'] = [os.path.split(file)[1] for file in files]\n",
    "\tmails['labels'] = labels\n",
    "\tmails['predictions'] = predictions\n",
    "\tdf = pd.DataFrame(mails)\n",
    "\tdf['result'] = np.where(df['predictions'] == df['labels'], \"CORRECT\", \"WRONG\")\n",
    "\tdf.set_index('files', inplace=True)\n",
    "\twith open('NBresults.txt', 'w') as f:\n",
    "\t\tf.write(df.to_string())\n",
    "\tprint(\"Results file created: {}\" . format(os.path.abspath('NBresults.txt')))\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
